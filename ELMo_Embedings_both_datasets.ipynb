{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/larissapoghosyan/Capstone_Project/blob/main/ELMo_Embedings_both_datasets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YUdYWcwnUCN5"
      },
      "outputs": [],
      "source": [
        "!pip install allennlp==0.9.0\n",
        "!pip install flair\n",
        "!pip install sacremoses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-JhO5oIT5r6"
      },
      "outputs": [],
      "source": [
        "from flair.data import Sentence\n",
        "from flair.embeddings import ELMoEmbeddings, DocumentPoolEmbeddings\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import warnings\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import h5py\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMDb"
      ],
      "metadata": {
        "id": "U0C67ru4r0gp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/IMDb_Reviews.csv',engine='python', error_bad_lines=False)"
      ],
      "metadata": {
        "id": "dI85_Hz4Iabq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d28c1a3f-4459-4921-a415-e3ace718e1e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
            "\n",
            "\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "Skipping line 27866: unexpected end of data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_prc20 = data.sample(int(data.shape[0]*0.2),\n",
        "                            random_state=22)"
      ],
      "metadata": {
        "id": "3bbGn5xX5oW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Intent Classification Dataset"
      ],
      "metadata": {
        "id": "7s7QkF1Zr3lw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_intent = pd.read_csv('/content/outofscope-intent-classification-dataset.csv')"
      ],
      "metadata": {
        "id": "jYvO5GNpyGvQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "np.random.seed(25)\n",
        "label_sample = np.random.choice(data_intent['label'].unique(),\n",
        "                                size=(10),\n",
        "                                replace=False)\n",
        "label_sample"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbWjRBKosF9t",
        "outputId": "e6724b27-b2eb-4ec5-cbbf-ba1414557c50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['what_can_i_ask_you', 'what_are_your_hobbies', 'order',\n",
              "       'change_accent', 'new_card', 'damaged_card', 'do_you_have_pets',\n",
              "       'last_maintenance', 'reminder_update', 'bill_balance'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_col_intent = np.array(data_intent['label']).reshape(data_intent.shape[0],1)"
      ],
      "metadata": {
        "id": "Dv--UPUQsOdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_sample = data[data['label'].isin(label_sample)]\n",
        "data_sample['label'] = le.fit_transform(data_sample['label'])"
      ],
      "metadata": {
        "id": "5Zi3P7kWsO2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ELMo embeddings"
      ],
      "metadata": {
        "id": "LFvk1zHQr5Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = []\n",
        "token_embedding = ELMoEmbeddings()\n",
        "document_embedding = DocumentPoolEmbeddings([token_embedding])\n",
        "# dataset_prc20 for IMDb and data_sample for Intent Clf dataset\n",
        "for sent in tqdm(dataset_prc20.iloc[:,0]):\n",
        "  sentence = Sentence(sent)\n",
        "  document_embedding.embed(sentence)\n",
        "  embeddings.append(sentence.embedding)"
      ],
      "metadata": {
        "id": "SaCOQj2urHrx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b435969-2a16-4481-df4a-8f325a88eb35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1500/1500 [00:35<00:00, 42.17it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings[0].shape"
      ],
      "metadata": {
        "id": "l5GjkteA3cx4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84bc663d-6ada-4f70-99b1-47edf4e6ad07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3072])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cpu'\n",
        "# stack the embeddings along axis 0  to obtain an embeddings tensor of size (data.shape[0], embeddings_size)\n",
        "embeddings_tensor = torch.stack(embeddings, dim=0).to(device)"
      ],
      "metadata": {
        "id": "xVgWNqlPIm3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_tensor.shape"
      ],
      "metadata": {
        "id": "RebL8t3E2-CK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ec10ab8-02ce-4a03-c4ff-1ec41b0745f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1500, 3072])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ELMo Embeddings for the IMDb Dataset"
      ],
      "metadata": {
        "id": "DlIFtYp3oSnR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hf_elmo = h5py.File('elmo_imdb_clf.h5', 'w')\n",
        "elmo_np = embeddings_tensor.numpy()\n",
        "elmo_imdb_hf = hf_elmo.create_dataset('elmo_imdb_clf', data=elmo_np)\n",
        "hf_elmo.close()"
      ],
      "metadata": {
        "id": "s_R005-S30Ux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ELMo Embeddings for the Intnet CLF Dataset"
      ],
      "metadata": {
        "id": "Y2fP1_DMoX0B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hf_elmo = h5py.File('elmo_intent_clf.h5', 'w')\n",
        "elmo_np = embeddings_tensor.numpy()\n",
        "elmo_imdb_hf = hf_elmo.create_dataset('elmo_intent_clf', data=elmo_np)\n",
        "hf_elmo.close()"
      ],
      "metadata": {
        "id": "VOcWODdVuS-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Measuring Inference Time for 1 datapoint on GPU (IMDb dataset)\n",
        " (from the final results ELMo is one of the best performing models, we check the inference time for comparison"
      ],
      "metadata": {
        "id": "hlUKd3BHAqe4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We sample 1000 data points randomly and then run the algorithm on those points\n",
        "data_1000_sample = data.sample(1000)\n",
        "data_1000_sample.shape\n",
        "label_col = np.array(data_1000_sample.iloc[:,-1]).reshape(data_1000_sample.shape[0],1)\n",
        "data_1000_sample.shape"
      ],
      "metadata": {
        "id": "2cjfKSFaA-AV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "071bbfc1-7443-4a26-c176-9c61c3c95379"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "\n",
        "embeddings = []\n",
        "token_embedding = ELMoEmbeddings()\n",
        "document_embedding = DocumentPoolEmbeddings([token_embedding])\n",
        "# giving data_1000_samples as input\n",
        "for sent in tqdm(data_1000_sample.iloc[:,0]):\n",
        "  sentence = Sentence(sent)\n",
        "  document_embedding.embed(sentence)\n",
        "  embeddings.append(sentence.embedding)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f'\\n Inference ran for {round((end_time -  start_time))} seconds for 1000 datapoints')\n",
        "print(f' \\n For 1 datapoint inference ran for {round((end_time -  start_time)/1000, 2)} seconds')"
      ],
      "metadata": {
        "id": "h34kUqbZA3uO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ced3886c-7bd8-410e-96ad-acdce8635e8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [07:26<00:00,  2.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Inference ran for 458 seconds for 1000 datapoints\n",
            " \n",
            " For 1 datapoint inference ran for 0.46 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cpu'\n",
        "embeddings_tensor = torch.stack(embeddings, dim=0).to(device)\n",
        "hf_elmo = embeddings_tensor.numpy()\n",
        "hf_elmo.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0mJQc2LHjIn",
        "outputId": "9627f61b-56ed-4f0b-e9e7-4aad2dbef5cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1000, 3072])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "\n",
        "with warnings.catch_warnings():\n",
        "    warnings.simplefilter(\"ignore\")\n",
        "    clf = LogisticRegression(solver = \"lbfgs\", random_state = 0)\n",
        "    clf.fit(hf_elmo, label_col)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f'\\n Inference ran for {round((end_time -  start_time))} seconds for 1000 datapoints')\n",
        "print(f' \\n For 1 datapoint inference ran for {round((end_time -  start_time)/1000, 2)} seconds')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chCbzh8KHnfg",
        "outputId": "d0516c21-fe06-48b4-a8db-e4e6bf5b729b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Inference ran for 0 seconds for 1000 datapoints\n",
            " \n",
            " For 1 datapoint inference ran for 0.0 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding the Embedding extraction inference time with logistic regression inference time we get 0.45 seconds for 1 data point"
      ],
      "metadata": {
        "id": "MQNyUxRnI3wR"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ELMo_Embedings_both_datasets.ipynb",
      "provenance": [],
      "background_execution": "on",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}